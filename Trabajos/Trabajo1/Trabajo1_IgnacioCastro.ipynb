{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo 1: Clasificación cuerpos celestiales\n",
    "\n",
    "<h1> Analisis Sloan Digital Sky Survey DR14</h1>\n",
    "\n",
    "### Ignacio Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota: \n",
    "## Para mostrar como afecta el mal procesamiento del dataset a los modelos, entrenameremos los 3 modelos 3 veces, una vez antes de equilibrar el dataset, luego una vez con el dataset equilibrado pero con variables que no son indicadoras de la clase del objeto, y finalmente con el dataset equilibrado y con las variables extras removidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primero importamos la base de datos y las librerias que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.722360e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.638140e+17</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>3.232740e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          objid          ra       dec         u         g         r         i  \\\n",
       "0  1.237650e+18  183.531326  0.089693  19.47406  17.04240  15.94699  15.50342   \n",
       "1  1.237650e+18  183.598371  0.135285  18.66280  17.21449  16.67637  16.48922   \n",
       "2  1.237650e+18  183.680207  0.126185  19.38298  18.19169  17.47428  17.08732   \n",
       "3  1.237650e+18  183.870529  0.049911  17.76536  16.60272  16.16116  15.98233   \n",
       "4  1.237650e+18  183.883288  0.102557  17.55025  16.26342  16.43869  16.55492   \n",
       "\n",
       "          z  run  rerun  camcol  field     specobjid   class  redshift  plate  \\\n",
       "0  15.22531  752    301       4    267  3.722360e+18    STAR -0.000009   3306   \n",
       "1  16.39150  752    301       4    267  3.638140e+17    STAR -0.000055    323   \n",
       "2  16.80125  752    301       4    268  3.232740e+17  GALAXY  0.123111    287   \n",
       "3  15.90438  752    301       4    269  3.722370e+18    STAR -0.000111   3306   \n",
       "4  16.61326  752    301       4    269  3.722370e+18    STAR  0.000590   3306   \n",
       "\n",
       "     mjd  fiberid  \n",
       "0  54922      491  \n",
       "1  51615      541  \n",
       "2  52023      513  \n",
       "3  54922      510  \n",
       "4  54922      512  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "space = pd.read_csv(\"datos/SDSS-DR14.csv\")\n",
    "space.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>DESCRIPCIONES VARIABLES</b>\n",
    "\n",
    "objid - Identificador de la fotografia<br>\n",
    "ra y dec - Angulos del telescopio<br>\n",
    "u,g,r,i,z - Respuesta de las bandas del telescopio a la luz en la escala de Thuan-Gunn<br>\n",
    "run - Numero del escaneo<br>\n",
    "rerun - Como se proceso la imagen<br>\n",
    "camcol - Columna de la camara<br>\n",
    "field - Numero de campo<br>\n",
    "specobjid - Identificador del objeto<br>\n",
    "class - Clase del objeto<br>\n",
    "redshift - redshift del objeto<br>\n",
    "plate - numero de placa<br>\n",
    "mjd - fecha juliana de la observacion<br>\n",
    "fibedid - Identificador de la fibra<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observación\n",
    "Estas características no tienen mucho sentido para predecir la clase objeto. Son en su mayoria datos referentes a la identificación del objeto, los ángulos del telescopio, la posicion, y datos de la camara. Los únicos que podrian tener relacion son las reaccion de las bandas del telescopio al flujo de luz (u,g,r,i,z) y el redshift, que indica si se esta acercando o alejando de la Tierra. Entonces, mientras es posible entrenar los modelos para que generen respuestas correctas probablemente no sean generalizables a otros problemas similares. Aun asi realizamos el analisis con los datos extras primero, para propósitos de aprendisaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objid        0\n",
       "ra           0\n",
       "dec          0\n",
       "u            0\n",
       "g            0\n",
       "r            0\n",
       "i            0\n",
       "z            0\n",
       "run          0\n",
       "rerun        0\n",
       "camcol       0\n",
       "field        0\n",
       "specobjid    0\n",
       "class        0\n",
       "redshift     0\n",
       "plate        0\n",
       "mjd          0\n",
       "fiberid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Primero vemos si hay valores nulos.\n",
    "space.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos que no hay datos nulos, procedemos a ver si el dataset esta equilibrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GALAXY    4998\n",
       "STAR      4152\n",
       "QSO        850\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos si hay desequilibrio\n",
    "space[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un claro desequilibrio en cuanto a la cantidad de QSO, esto lo arreglaremos despues pero de momento lo dejaremos asi para ver como afecta a los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      "objid        10000 non-null float64\n",
      "ra           10000 non-null float64\n",
      "dec          10000 non-null float64\n",
      "u            10000 non-null float64\n",
      "g            10000 non-null float64\n",
      "r            10000 non-null float64\n",
      "i            10000 non-null float64\n",
      "z            10000 non-null float64\n",
      "run          10000 non-null int64\n",
      "rerun        10000 non-null int64\n",
      "camcol       10000 non-null int64\n",
      "field        10000 non-null int64\n",
      "specobjid    10000 non-null float64\n",
      "class        10000 non-null object\n",
      "redshift     10000 non-null float64\n",
      "plate        10000 non-null int64\n",
      "mjd          10000 non-null int64\n",
      "fiberid      10000 non-null int64\n",
      "dtypes: float64(10), int64(7), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Vemos los tipos.\n",
    "space.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.722360e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.638140e+17</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>3.232740e+17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          objid          ra       dec         u         g         r         i  \\\n",
       "0  1.237650e+18  183.531326  0.089693  19.47406  17.04240  15.94699  15.50342   \n",
       "1  1.237650e+18  183.598371  0.135285  18.66280  17.21449  16.67637  16.48922   \n",
       "2  1.237650e+18  183.680207  0.126185  19.38298  18.19169  17.47428  17.08732   \n",
       "3  1.237650e+18  183.870529  0.049911  17.76536  16.60272  16.16116  15.98233   \n",
       "4  1.237650e+18  183.883288  0.102557  17.55025  16.26342  16.43869  16.55492   \n",
       "\n",
       "          z  run  rerun  camcol  field     specobjid  class  redshift  plate  \\\n",
       "0  15.22531  752    301       4    267  3.722360e+18      0 -0.000009   3306   \n",
       "1  16.39150  752    301       4    267  3.638140e+17      0 -0.000055    323   \n",
       "2  16.80125  752    301       4    268  3.232740e+17      1  0.123111    287   \n",
       "3  15.90438  752    301       4    269  3.722370e+18      0 -0.000111   3306   \n",
       "4  16.61326  752    301       4    269  3.722370e+18      0  0.000590   3306   \n",
       "\n",
       "     mjd  fiberid  \n",
       "0  54922      491  \n",
       "1  51615      541  \n",
       "2  52023      513  \n",
       "3  54922      510  \n",
       "4  54922      512  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Como hay un valor no numerico lo pasamos a numerico.\n",
    "classdict =\t{\n",
    "    \"STAR\": 0,\n",
    "    \"GALAXY\": 1,\n",
    "    \"QSO\": 2\n",
    "}\n",
    "\n",
    "def classnum(g):\n",
    "    return classdict[g]\n",
    "\n",
    "space['class'] = space['class'].apply(classnum)\n",
    "space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      "objid        10000 non-null float64\n",
      "ra           10000 non-null float64\n",
      "dec          10000 non-null float64\n",
      "u            10000 non-null float64\n",
      "g            10000 non-null float64\n",
      "r            10000 non-null float64\n",
      "i            10000 non-null float64\n",
      "z            10000 non-null float64\n",
      "run          10000 non-null int64\n",
      "rerun        10000 non-null int64\n",
      "camcol       10000 non-null int64\n",
      "field        10000 non-null int64\n",
      "specobjid    10000 non-null float64\n",
      "class        10000 non-null int64\n",
      "redshift     10000 non-null float64\n",
      "plate        10000 non-null int64\n",
      "mjd          10000 non-null int64\n",
      "fiberid      10000 non-null int64\n",
      "dtypes: float64(10), int64(8)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos que ahora sea todo numerico.\n",
    "space.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el dataset esta listo para ser procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los parametros y nuestras clases.\n",
    "parname=list(space.columns)\n",
    "parname.remove(\"class\")\n",
    "X = space[parname].to_numpy()\n",
    "Y = space[\"class\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos le muestreo para entrenamiento y testeo.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .3, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero probaremos el rendimiento de los modelos con el dataset desequilibrado, para ver como los afecta esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1290    8    2]\n",
      " [   2 1439   12]\n",
      " [   0   30  217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1300\n",
      "           1       0.97      0.99      0.98      1453\n",
      "           2       0.94      0.88      0.91       247\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3000\n",
      "   macro avg       0.97      0.95      0.96      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento del arbol de decision.\n",
    "from sklearn import tree\n",
    "tclf = tree.DecisionTreeClassifier()\n",
    "tclf.fit(X_train,Y_train)\n",
    "tree_pred = tclf.predict(X_test)\n",
    "tree_matrix = confusion_matrix(Y_test, tree_pred)\n",
    "print(tree_matrix)\n",
    "print(classification_report(Y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El arbol de decision tiene un buen rendimiento, tiene buena precision para los tres casos, es decir, si dice que un caso pertenece a cierta clase, es probable que este correcto. Tambien presenta un buen recall, o capacidad para identificar los casos (es decir, de los casos que pertenecen a una clase, cuantos el modelo reconoce que pertenecen a esa clase). Ambas medidas son un poco peores para la clase QSO, probablemente debido a la baja frecuencia de este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1296    4    0]\n",
      " [   6 1440    7]\n",
      " [   0   24  223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1300\n",
      "           1       0.98      0.99      0.99      1453\n",
      "           2       0.97      0.90      0.94       247\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3000\n",
      "   macro avg       0.98      0.96      0.97      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de un random forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "fclf = RandomForestClassifier(n_estimators=10)\n",
    "fclf.fit(X_train,Y_train)\n",
    "forest_pred = fclf.predict(X_test)\n",
    "forest_matrix = confusion_matrix(Y_test, forest_pred)\n",
    "print(forest_matrix)\n",
    "print(classification_report(Y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El random forest tiene mejor rendimiento que el arbol de decision, lo que tiene sentido considerando que el random forest es el promedio de varios arboles de desicion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 971  329    0]\n",
      " [  32 1421    0]\n",
      " [  50  197    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.83      1300\n",
      "           1       0.73      0.98      0.84      1453\n",
      "           2       0.00      0.00      0.00       247\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      3000\n",
      "   macro avg       0.55      0.57      0.55      3000\n",
      "weighted avg       0.75      0.80      0.76      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de la regresion linear.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train, Y_train)\n",
    "logreg_pred = LogReg.predict(X_test)\n",
    "logreg_matrix = confusion_matrix(Y_test, logreg_pred)\n",
    "print(logreg_matrix)\n",
    "print(classification_report(Y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos ver que la regresión logística funciona muy mal en un dataset desequilibrado. Es completamente incapaz de identificar un QSO, e incluso se vieron afectados la precision y recall para las otras clases. Aumento la probabilidad de que clasifique erroneamente como galaxia un caso, y tiene mas dificultad para reconocer estrellas.\n",
    "\n",
    "##### De hecho, viendo la matriz de confusion, el algoritmo se entreno para no decir nunca que un caso pertenece a la clase QSO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora que vimos como funciona con el dataset desequilibrado, procederemos a equilibrarlo y probar nuevamente. Usaremos Up-Sampling o Oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "#Cambiamos el nombre de la columna porque al llamarse \"class\" causa problemas de syntax.\n",
    "space2=space.rename(columns={\"class\": \"clase\"})\n",
    "# Separamos el dataset en los casos mayoritarios y minoritarios.\n",
    "df_major = space2[space2.clase<2]\n",
    "df_minor = space2[space2.clase==2]\n",
    "#Para numero de samples usamos el promedio de los otros 2 casos.\n",
    "numsamples=(int)(np.sum(df_major['clase'].value_counts())/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4998\n",
       "2    4575\n",
       "0    4152\n",
       "Name: clase, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacemos up-sampling del caso minoritario.\n",
    "df_minor_upsampled = resample(df_minor, \n",
    "                                 replace=True,\n",
    "                                 n_samples=numsamples,\n",
    "                                 random_state=123)\n",
    " \n",
    "#Combinamos los casos mayoritarios con el nuevo minoritario.\n",
    "df_upsampled = pd.concat([df_major, df_minor_upsampled])\n",
    " \n",
    "#Comprobamos que hora este balanceado.\n",
    "df_upsampled.clase.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora que el dataset esta balanceado, repetimos los pasos anteriores para entrenamiento de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos los parametros y nuestras clases.\n",
    "parname=list(df_upsampled.columns)\n",
    "parname.remove(\"clase\")\n",
    "X = df_upsampled[parname].to_numpy()\n",
    "Y = df_upsampled[\"clase\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos le muestreo para entrenamiento y testeo.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .3, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1229    0    0]\n",
      " [   2 1498   19]\n",
      " [   0    4 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1229\n",
      "           1       1.00      0.99      0.99      1519\n",
      "           2       0.99      1.00      0.99      1370\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4118\n",
      "   macro avg       0.99      0.99      0.99      4118\n",
      "weighted avg       0.99      0.99      0.99      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento del arbol de decision.\n",
    "from sklearn import tree\n",
    "tclf = tree.DecisionTreeClassifier()\n",
    "tclf.fit(X_train,Y_train)\n",
    "tree_pred = tclf.predict(X_test)\n",
    "tree_matrix = confusion_matrix(Y_test, tree_pred)\n",
    "print(tree_matrix)\n",
    "print(classification_report(Y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos que al equilibrar el dataset, mejora levemente el rendimiento del arbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1229    0    0]\n",
      " [   9 1501    9]\n",
      " [   0    5 1365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1229\n",
      "           1       1.00      0.99      0.99      1519\n",
      "           2       0.99      1.00      0.99      1370\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4118\n",
      "   macro avg       0.99      0.99      0.99      4118\n",
      "weighted avg       0.99      0.99      0.99      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de un random forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "fclf = RandomForestClassifier(n_estimators=10)\n",
    "fclf.fit(X_train,Y_train)\n",
    "forest_pred = fclf.predict(X_test)\n",
    "forest_matrix = confusion_matrix(Y_test, forest_pred)\n",
    "print(forest_matrix)\n",
    "print(classification_report(Y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El random forest, como el arbol de desicion, tambien presenta mejora en todas las medidas de precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 863  303   63]\n",
      " [  40 1476    3]\n",
      " [ 253 1113    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      1229\n",
      "           1       0.51      0.97      0.67      1519\n",
      "           2       0.06      0.00      0.01      1370\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      4118\n",
      "   macro avg       0.44      0.56      0.47      4118\n",
      "weighted avg       0.43      0.57      0.46      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de la regresion linear.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Configuramos logreg para funcionar con multiples clases.\n",
    "LogReg = LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train, Y_train)\n",
    "logreg_pred = LogReg.predict(X_test)\n",
    "logreg_matrix = confusion_matrix(Y_test, logreg_pred)\n",
    "print(logreg_matrix)\n",
    "print(classification_report(Y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos ver un pequeño aumento en la precision y recall par objeto QSO, pero sigue siendo bastante malo. De hecho el upsampling bajo la precision y recall en los otros casos considerablemente para dar una minuscula mejora en el caso de QSO, lo que es un mal trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando el rendimiento de los modelos, podemos ver que los modelos basados en arboles como el decision tree y el random forest funcionan bien aun con datasets desequilibrados, por lo que podrían ser una buena medida para lidiar con estos. En cambio la regresión logística y otros modelos lineales sufren mucha perdida de utilidad con datasets desequilibrado. \n",
    "\n",
    "### De los tres modelos vistos, la regresión logística tiene la ventaja de poder predecir probabilidades y ser mas simple de entender, pues consiste solo de una serie de coeficientes, pero tiene problemas con dataset desequilibrados. El árbol de decisión es mas complejo de representar pues esta formado por varios nodos y se centra en clasificar los objetos, ademas corren el riesgo de sobreajustarse a un dataset, pero tienen un mejor rendimiento al momento de clasificar datasets, aunque esten desequilibrados. Finalmente los random forest heredan las ventajas de los árboles de decisión, y su naturaleza aleatoria ayuda a evitar el sobreajuste, pero esta aleatoridad también puede causar problemas a veces. Además al ser un conjunto de árboles de decisión, es el mas complejo de estos 3 modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veamos cuales son las características mas importantes para la clasificación segun cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es estrella son en orden descendiente: objid, specobjid, mjd, run, fiberid, plate, rerun, dec, ra, field.\n",
      "\n",
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es galaxia son en orden descendiente: specobjid, objid, mjd, run, plate, fiberid, rerun, ra, dec, field.\n",
      "\n",
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es quasar son en orden descendiente: specobjid, objid, mjd, run, fiberid, plate, dec, field, z, i.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#La regresion lineal con multiples categorias calcula la probabilidad para cada caso y elije la mayor.\n",
    "#Por esto, habrán 3 grupos de coeficientes.\n",
    "#Primero convertimos los coeficientes a valor absoluto.\n",
    "logcoef0=list(map(abs, LogReg.coef_[0].tolist()))\n",
    "logcoef1=list(map(abs, LogReg.coef_[1].tolist()))\n",
    "logcoef2=list(map(abs, LogReg.coef_[2].tolist()))\n",
    "#Luego ordenamos las variables de mayor coeficiente a menor.\n",
    "plr0=[x for _,x in sorted(zip(logcoef0,parname),reverse=True)]\n",
    "plr1=[x for _,x in sorted(zip(logcoef1,parname),reverse=True)]\n",
    "plr2=[x for _,x in sorted(zip(logcoef2,parname),reverse=True)]\n",
    "rlvalues=[plr0,plr1,plr2]\n",
    "\n",
    "#Cuantos parametros importantes quiero que diga.\n",
    "numero_parametros=10\n",
    "\n",
    "for n,i in enumerate([\"estrella\",\"galaxia\",\"quasar\"]):\n",
    "    tempst=\"Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es {0} son en orden descendiente: \".format(i)\n",
    "    for j in range(numero_parametros-1):\n",
    "        tempst= tempst+rlvalues[n][j]+\", \"\n",
    "    tempst= tempst+rlvalues[n][j+1]+\".\"\n",
    "    print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La regresión logística se centra en valores que no deberian influir en la naturaleza del objeto, como las id, las fechas o el numero del scaneo. Es posible que el patron que se usa para asignar IDs varie segun el objeto y por eso le este asignando tanto peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que el árbol de decisión clasifique un objeto son, en orden descendiente: redshift, g, u, z, field, specobjid, ra, r, mjd, plate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ahora veamos las mas importantes para el árbol de decisión.\n",
    "#Esto es un poco mas facil porque el arbol incluye una funcion que nos dice las variables mas importantes.\n",
    "#tclf.feature_importances_\n",
    "tparnam=[x for _,x in sorted(zip(tclf.feature_importances_.tolist(),parname),reverse=True)]\n",
    "\n",
    "tempst=\"Las caracteristicas mas importantes para que el árbol de decisión clasifique un objeto son, en orden descendiente: \"\n",
    "for i in range(numero_parametros-1):\n",
    "    tempst= tempst+tparnam[i]+\", \"\n",
    "tempst= tempst+tparnam[i+1]+\".\"\n",
    "print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se centra menos en identificadores y da mas importancia a valores de ubicacion y los niveles de luz los del objeto, que son mejores inicadores de su naturaleza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que el random forest clasifique un objeto son, en orden descendiente: redshift, i, z, r, mjd, specobjid, g, plate, u, dec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ahora veamos las mas importantes para el random forest.\n",
    "#Igualmente es más facil porque incluye una funcion que nos dice las variables mas importantes.\n",
    "#fclf.feature_importances_\n",
    "tparnam=[x for _,x in sorted(zip(fclf.feature_importances_.tolist(),parname),reverse=True)]\n",
    "\n",
    "tempst=\"Las caracteristicas mas importantes para que el random forest clasifique un objeto son, en orden descendiente: \"\n",
    "for i in range(numero_parametros-1):\n",
    "    tempst= tempst+tparnam[i]+\", \"\n",
    "tempst= tempst+tparnam[i+1]+\".\"\n",
    "print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Al igual que el árbol, se centra menos en identificadores y da mas importancia a valores de ubicacion y los niveles de luz de los del objeto, que son mejores inicadores de su naturaleza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ultimo, hagamos un ultimo ajuste. Como dijimos inicialmente la mayoria de las variables son identificdores del telescopio, la camara o la imagen. Entonces ahora hagamos esto usando la información que pertenece al objeto celestial en si: u, g, r, i, z, que indican la luz que recibe el telescopio desde ol objeto en el espacio, y redshift que es un cambio en la longitud de onda de la luz que nos indica si el objeto se esta acercando o alejando de la Tierra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parname2=[\"u\",\"g\",\"r\",\"i\",\"z\",\"redshift\"]\n",
    "#Dividimos los parametros y nuestras clases.\n",
    "X = df_upsampled[parname2].to_numpy()\n",
    "Y = df_upsampled[\"clase\"].to_numpy()\n",
    "#Hacemos le muestreo para entrenamiento y testeo.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .3, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1229    0    0]\n",
      " [   2 1502   15]\n",
      " [   0    4 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1229\n",
      "           1       1.00      0.99      0.99      1519\n",
      "           2       0.99      1.00      0.99      1370\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      4118\n",
      "   macro avg       0.99      1.00      1.00      4118\n",
      "weighted avg       0.99      0.99      0.99      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento del arbol de decision.\n",
    "from sklearn import tree\n",
    "tclf = tree.DecisionTreeClassifier()\n",
    "tclf.fit(X_train,Y_train)\n",
    "tree_pred = tclf.predict(X_test)\n",
    "tree_matrix = confusion_matrix(Y_test, tree_pred)\n",
    "print(tree_matrix)\n",
    "print(classification_report(Y_test, tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1228    1    0]\n",
      " [   8 1501   10]\n",
      " [   0    1 1369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1229\n",
      "           1       1.00      0.99      0.99      1519\n",
      "           2       0.99      1.00      1.00      1370\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      4118\n",
      "   macro avg       0.99      1.00      1.00      4118\n",
      "weighted avg       1.00      1.00      1.00      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de un random forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "fclf = RandomForestClassifier(n_estimators=10)\n",
    "fclf.fit(X_train,Y_train)\n",
    "forest_pred = fclf.predict(X_test)\n",
    "forest_matrix = confusion_matrix(Y_test, forest_pred)\n",
    "print(forest_matrix)\n",
    "print(classification_report(Y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1202   23    4]\n",
      " [  81 1427   11]\n",
      " [   0   36 1334]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      1229\n",
      "           1       0.96      0.94      0.95      1519\n",
      "           2       0.99      0.97      0.98      1370\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      4118\n",
      "   macro avg       0.96      0.96      0.96      4118\n",
      "weighted avg       0.96      0.96      0.96      4118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probamos el rendimiento de la regresion linear.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Configuramos logreg para funcionar con multiples clases.\n",
    "LogReg = LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train, Y_train)\n",
    "logreg_pred = LogReg.predict(X_test)\n",
    "logreg_matrix = confusion_matrix(Y_test, logreg_pred)\n",
    "print(logreg_matrix)\n",
    "print(classification_report(Y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos apreciar que el árbol y el bosque mantienen su buen rendimiento, pero la regresion linear experimenta una masiva mejora, por lo que podemos teorizar que los modelos lineales se ven más afectado por datos inutiles que los algoritmos basados en arboles.\n",
    "\n",
    "#### La regresión logistica funcionara mejor en un dataset equilibrado y con parametros que afecten la clasificación de objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora veamos a que parametros les dan importancia los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es estrella son en orden descendiente: redshift, g, z, r, u, i.\n",
      "\n",
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es galaxia son en orden descendiente: redshift, r, z, g, u, i.\n",
      "\n",
      "Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es quasar son en orden descendiente: redshift, g, u, z, r, i.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#La regresion lineal con multiples categorias calcula la probabilidad para cada caso y elije la mayor.\n",
    "#Por esto, habrán 3 grupos de coeficientes.\n",
    "#Primero convertimos los coeficientes a valor absoluto.\n",
    "logcoef0=list(map(abs, LogReg.coef_[0].tolist()))\n",
    "logcoef1=list(map(abs, LogReg.coef_[1].tolist()))\n",
    "logcoef2=list(map(abs, LogReg.coef_[2].tolist()))\n",
    "#Luego ordenamos las variables de mayor coeficiente a menor.\n",
    "plr0=[x for _,x in sorted(zip(logcoef0,parname2),reverse=True)]\n",
    "plr1=[x for _,x in sorted(zip(logcoef1,parname2),reverse=True)]\n",
    "plr2=[x for _,x in sorted(zip(logcoef2,parname2),reverse=True)]\n",
    "rlvalues=[plr0,plr1,plr2]\n",
    "\n",
    "#Cuantos parametros importantes quiero que diga.\n",
    "numero_parametros=len(parname2)\n",
    "\n",
    "for n,i in enumerate([\"estrella\",\"galaxia\",\"quasar\"]):\n",
    "    tempst=\"Las caracteristicas mas importantes para que la regresion lineal decida si un objeto es {0} son en orden descendiente: \".format(i)\n",
    "    for j in range(numero_parametros-1):\n",
    "        tempst= tempst+rlvalues[n][j]+\", \"\n",
    "    tempst= tempst+rlvalues[n][j+1]+\".\"\n",
    "    print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Podemos ver que además de la mejora en precision y recall, ahora el algoritmo es mas consistente. Todas las clases le dan la mayor importancia  al redshift, mederada importancia a g y la menor importancia a i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que el árbol de decisión clasifique un objeto son, en orden descendiente: redshift, u, g, z, i, r.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ahora veamos las mas importantes para el árbol de decisión.\n",
    "#Esto es un poco mas facil porque el arbol incluye una funcion que nos dice las variables mas importantes.\n",
    "#tclf.feature_importances_\n",
    "tparnam=[x for _,x in sorted(zip(tclf.feature_importances_.tolist(),parname2),reverse=True)]\n",
    "\n",
    "tempst=\"Las caracteristicas mas importantes para que el árbol de decisión clasifique un objeto son, en orden descendiente: \"\n",
    "for i in range(numero_parametros-1):\n",
    "    tempst= tempst+tparnam[i]+\", \"\n",
    "tempst= tempst+tparnam[i+1]+\".\"\n",
    "print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Se destaca que al igual que laa regresión logistica, el árbol le da mayor importancia al redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las caracteristicas mas importantes para que el random forest clasifique un objeto son, en orden descendiente: redshift, z, r, i, u, g.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ahora veamos las mas importantes para el random forest.\n",
    "#Igualmente es más facil porque incluye una funcion que nos dice las variables mas importantes.\n",
    "#fclf.feature_importances_\n",
    "tparnam=[x for _,x in sorted(zip(fclf.feature_importances_.tolist(),parname2),reverse=True)]\n",
    "\n",
    "tempst=\"Las caracteristicas mas importantes para que el random forest clasifique un objeto son, en orden descendiente: \"\n",
    "for i in range(numero_parametros-1):\n",
    "    tempst= tempst+tparnam[i]+\", \"\n",
    "tempst= tempst+tparnam[i+1]+\".\"\n",
    "print(tempst+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El bosque también prioritiza el redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entonces, podemos decir que el factor mas influyente en la clasificación sera el redshift del objeto, seguido por las varias variables de medicion de luz, que son priorizadas distinto segun el modelo usado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
